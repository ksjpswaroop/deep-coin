{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "total_series_length = 50000\n",
    "truncated_backprop_length = 15\n",
    "state_size = 4\n",
    "num_classes = 2\n",
    "echo_step = 3\n",
    "batch_size = 5\n",
    "num_batches = total_series_length // batch_size // truncated_backprop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateData():\n",
    "    x = np.array(np.random.choice(2, total_series_length, p=[0.5, 0.5]))\n",
    "    y = np.roll(x, echo_step)\n",
    "    y[0:echo_step] = 0\n",
    "    \n",
    "    x = x.reshape((batch_size, -1))\n",
    "    y = y.reshape((batch_size, -1))\n",
    "    \n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_placeholder = tf.placeholder(tf.float32, [batch_size, truncated_backprop_length])\n",
    "y_placeholder = tf.placeholder(tf.int32, [batch_size, truncated_backprop_length])\n",
    "\n",
    "init_state = tf.placeholder(tf.float32, [batch_size, state_size])\n",
    "\n",
    "W2 = tf.Variable(np.random.rand(state_size, num_classes), dtype=tf.float32)\n",
    "b2 = tf.Variable(np.zeros((1, num_classes)), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_series = tf.split(x_placeholder, truncated_backprop_length, 1)\n",
    "label_series = tf.unstack(y_placeholder, axis=1)\n",
    "\n",
    "cell = rnn.BasicRNNCell(state_size)\n",
    "state_series, current_state = rnn.static_rnn(cell, input_series, init_state)\n",
    "\n",
    "logit_series = [tf.matmul(state, W2) + b2 for state in state_series]\n",
    "prediction_series = [tf.nn.softmax(logits) for logits in logit_series]\n",
    "\n",
    "loss = [tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels) for logits, labels in zip(logit_series, label_series)]\n",
    "total_loss = tf.reduce_mean(loss)\n",
    "\n",
    "train_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(loss_list, prediction_series, batchX, batchY):\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.cla()\n",
    "    plt.plot(loss_list)\n",
    "\n",
    "    for batch_series_idx in range(5):\n",
    "        one_hot_output_series = np.array(prediction_series)[:, batch_series_idx, :]\n",
    "        single_output_series = np.array([(1 if out[0] < 0.5 else 0) for out in one_hot_output_series])\n",
    "\n",
    "        plt.subplot(2, 3, batch_series_idx + 2)\n",
    "        plt.cla()\n",
    "        plt.axis([0, truncated_backprop_length, 0, 2])\n",
    "        left_offset = range(truncated_backprop_length)\n",
    "        plt.bar(left_offset, batchX[batch_series_idx, :], width=1, color=\"blue\")\n",
    "        plt.bar(left_offset, batchY[batch_series_idx, :] * 0.5, width=1, color=\"red\")\n",
    "        plt.bar(left_offset, single_output_series * 0.3, width=1, color=\"green\")\n",
    "\n",
    "    plt.draw()\n",
    "    plt.pause(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f655c850860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data 0\n",
      "Step 0 Loss 0.692686\n",
      "Step 100 Loss 0.0096617\n",
      "Step 200 Loss 0.00514435\n",
      "Step 300 Loss 0.00281625\n",
      "Step 400 Loss 0.00237747\n",
      "Step 500 Loss 0.00180663\n",
      "Step 600 Loss 0.00147134\n",
      "New data 1\n",
      "Step 0 Loss 0.134831\n",
      "Step 100 Loss 0.00111446\n",
      "Step 200 Loss 0.00111941\n",
      "Step 300 Loss 0.00083331\n",
      "Step 400 Loss 0.000821429\n",
      "Step 500 Loss 0.000766714\n",
      "Step 600 Loss 0.000666422\n",
      "New data 2\n",
      "Step 0 Loss 0.298237\n",
      "Step 100 Loss 0.00176218\n",
      "Step 200 Loss 0.00139891\n",
      "Step 300 Loss 0.00129052\n",
      "Step 400 Loss 0.00106614\n",
      "Step 500 Loss 0.000941458\n",
      "Step 600 Loss 0.000933247\n",
      "New data 3\n",
      "Step 0 Loss 0.20232\n",
      "Step 100 Loss 0.000888679\n",
      "Step 200 Loss 0.000723841\n",
      "Step 300 Loss 0.00074379\n",
      "Step 400 Loss 0.000672682\n",
      "Step 500 Loss 0.000683257\n",
      "Step 600 Loss 0.000575795\n",
      "New data 4\n",
      "Step 0 Loss 0.145318\n",
      "Step 100 Loss 0.000588189\n",
      "Step 200 Loss 0.000564512\n",
      "Step 300 Loss 0.00048849\n",
      "Step 400 Loss 0.000473344\n",
      "Step 500 Loss 0.000424787\n",
      "Step 600 Loss 0.000337021\n",
      "New data 5\n",
      "Step 0 Loss 0.151616\n",
      "Step 100 Loss 0.000423081\n",
      "Step 200 Loss 0.000350154\n",
      "Step 300 Loss 0.000362088\n",
      "Step 400 Loss 0.000339413\n",
      "Step 500 Loss 0.000325385\n",
      "Step 600 Loss 0.000334307\n",
      "New data 6\n",
      "Step 0 Loss 0.307835\n",
      "Step 100 Loss 0.000376455\n",
      "Step 200 Loss 0.000326362\n",
      "Step 300 Loss 0.000320656\n",
      "Step 400 Loss 0.000416246\n",
      "Step 500 Loss 0.00029267\n",
      "Step 600 Loss 0.000309664\n",
      "New data 7\n",
      "Step 0 Loss 0.253118\n",
      "Step 100 Loss 0.000307951\n",
      "Step 200 Loss 0.000296475\n",
      "Step 300 Loss 0.000292253\n",
      "Step 400 Loss 0.000244023\n",
      "Step 500 Loss 0.000239092\n",
      "Step 600 Loss 0.000256344\n",
      "New data 8\n",
      "Step 0 Loss 0.289139\n",
      "Step 100 Loss 0.000255948\n",
      "Step 200 Loss 0.000272539\n",
      "Step 300 Loss 0.00024747\n",
      "Step 400 Loss 0.0002619\n",
      "Step 500 Loss 0.000208333\n",
      "Step 600 Loss 0.000225374\n",
      "New data 9\n",
      "Step 0 Loss 0.343125\n",
      "Step 100 Loss 0.000228907\n",
      "Step 200 Loss 0.000215504\n",
      "Step 300 Loss 0.000210391\n",
      "Step 400 Loss 0.000202436\n",
      "Step 500 Loss 0.000206504\n",
      "Step 600 Loss 0.000203869\n",
      "New data 10\n",
      "Step 0 Loss 0.146337\n",
      "Step 100 Loss 0.000203895\n",
      "Step 200 Loss 0.000178737\n",
      "Step 300 Loss 0.000190411\n",
      "Step 400 Loss 0.000195724\n",
      "Step 500 Loss 0.000157447\n",
      "Step 600 Loss 0.000196108\n",
      "New data 11\n",
      "Step 0 Loss 0.153761\n",
      "Step 100 Loss 0.00017298\n",
      "Step 200 Loss 0.000150639\n",
      "Step 300 Loss 0.000166057\n",
      "Step 400 Loss 0.000169883\n",
      "Step 500 Loss 0.000170458\n",
      "Step 600 Loss 0.000160727\n",
      "New data 12\n",
      "Step 0 Loss 0.167077\n",
      "Step 100 Loss 0.00013561\n",
      "Step 200 Loss 0.00014824\n",
      "Step 300 Loss 0.000155052\n",
      "Step 400 Loss 0.000168555\n",
      "Step 500 Loss 0.000156264\n",
      "Step 600 Loss 0.000147016\n",
      "New data 13\n",
      "Step 0 Loss 0.291798\n",
      "Step 100 Loss 0.000197098\n",
      "Step 200 Loss 0.000180989\n",
      "Step 300 Loss 0.000171626\n",
      "Step 400 Loss 0.000159207\n",
      "Step 500 Loss 0.000151861\n",
      "Step 600 Loss 0.00015627\n",
      "New data 14\n",
      "Step 0 Loss 0.41126\n",
      "Step 100 Loss 0.000159427\n",
      "Step 200 Loss 0.000143781\n",
      "Step 300 Loss 0.000130614\n",
      "Step 400 Loss 0.000136428\n",
      "Step 500 Loss 0.000125602\n",
      "Step 600 Loss 0.000128213\n",
      "New data 15\n",
      "Step 0 Loss 0.291622\n",
      "Step 100 Loss 0.000164747\n",
      "Step 200 Loss 0.000141551\n",
      "Step 300 Loss 0.000147919\n",
      "Step 400 Loss 0.000145655\n",
      "Step 500 Loss 0.000148568\n",
      "Step 600 Loss 0.000152196\n",
      "New data 16\n",
      "Step 0 Loss 0.291367\n",
      "Step 100 Loss 0.000139071\n",
      "Step 200 Loss 0.000117812\n",
      "Step 300 Loss 0.000111695\n",
      "Step 400 Loss 0.000139314\n",
      "Step 500 Loss 0.000114205\n",
      "Step 600 Loss 0.000127167\n",
      "New data 17\n",
      "Step 0 Loss 0.182114\n",
      "Step 100 Loss 0.000108965\n",
      "Step 200 Loss 0.000128194\n",
      "Step 300 Loss 0.000118538\n",
      "Step 400 Loss 0.000123193\n",
      "Step 500 Loss 0.000117176\n",
      "Step 600 Loss 0.000104068\n",
      "New data 18\n",
      "Step 0 Loss 0.279211\n",
      "Step 100 Loss 0.000121351\n",
      "Step 200 Loss 0.000108596\n",
      "Step 300 Loss 0.000114311\n",
      "Step 400 Loss 0.000105459\n",
      "Step 500 Loss 9.60469e-05\n",
      "Step 600 Loss 9.33566e-05\n",
      "New data 19\n",
      "Step 0 Loss 0.169568\n",
      "Step 100 Loss 0.000124885\n",
      "Step 200 Loss 0.000125009\n",
      "Step 300 Loss 0.00012975\n",
      "Step 400 Loss 0.000129802\n",
      "Step 500 Loss 0.000100902\n",
      "Step 600 Loss 0.000104907\n",
      "New data 20\n",
      "Step 0 Loss 0.270563\n",
      "Step 100 Loss 9.89188e-05\n",
      "Step 200 Loss 0.000111213\n",
      "Step 300 Loss 0.000102276\n",
      "Step 400 Loss 9.47719e-05\n",
      "Step 500 Loss 0.00010981\n",
      "Step 600 Loss 9.44497e-05\n",
      "New data 21\n",
      "Step 0 Loss 0.174417\n",
      "Step 100 Loss 9.47646e-05\n",
      "Step 200 Loss 9.92511e-05\n",
      "Step 300 Loss 8.67963e-05\n",
      "Step 400 Loss 8.95884e-05\n",
      "Step 500 Loss 9.74812e-05\n",
      "Step 600 Loss 8.72161e-05\n",
      "New data 22\n",
      "Step 0 Loss 0.143243\n",
      "Step 100 Loss 9.10521e-05\n",
      "Step 200 Loss 0.000100469\n",
      "Step 300 Loss 8.85112e-05\n",
      "Step 400 Loss 8.96492e-05\n",
      "Step 500 Loss 9.66165e-05\n",
      "Step 600 Loss 8.07283e-05\n",
      "New data 23\n",
      "Step 0 Loss 0.155936\n",
      "Step 100 Loss 8.82602e-05\n",
      "Step 200 Loss 8.72032e-05\n",
      "Step 300 Loss 9.43584e-05\n",
      "Step 400 Loss 8.6188e-05\n",
      "Step 500 Loss 8.08382e-05\n",
      "Step 600 Loss 8.12834e-05\n",
      "New data 24\n",
      "Step 0 Loss 0.198526\n",
      "Step 100 Loss 7.58876e-05\n",
      "Step 200 Loss 8.67439e-05\n",
      "Step 300 Loss 8.30616e-05\n",
      "Step 400 Loss 7.80599e-05\n",
      "Step 500 Loss 8.09524e-05\n",
      "Step 600 Loss 7.85354e-05\n",
      "New data 25\n",
      "Step 0 Loss 0.134409\n",
      "Step 100 Loss 7.29822e-05\n",
      "Step 200 Loss 7.64866e-05\n",
      "Step 300 Loss 6.78582e-05\n",
      "Step 400 Loss 7.21638e-05\n",
      "Step 500 Loss 7.4532e-05\n",
      "Step 600 Loss 7.18806e-05\n",
      "New data 26\n",
      "Step 0 Loss 0.199851\n",
      "Step 100 Loss 7.7903e-05\n",
      "Step 200 Loss 7.21734e-05\n",
      "Step 300 Loss 0.0001253\n",
      "Step 400 Loss 7.77599e-05\n",
      "Step 500 Loss 7.94826e-05\n",
      "Step 600 Loss 7.38263e-05\n",
      "New data 27\n",
      "Step 0 Loss 0.285672\n",
      "Step 100 Loss 7.07195e-05\n",
      "Step 200 Loss 9.1331e-05\n",
      "Step 300 Loss 7.41966e-05\n",
      "Step 400 Loss 7.57193e-05\n",
      "Step 500 Loss 7.31512e-05\n",
      "Step 600 Loss 7.39825e-05\n",
      "New data 28\n",
      "Step 0 Loss 0.219172\n",
      "Step 100 Loss 6.86771e-05\n",
      "Step 200 Loss 6.98025e-05\n",
      "Step 300 Loss 6.80319e-05\n",
      "Step 400 Loss 7.84975e-05\n",
      "Step 500 Loss 7.21483e-05\n",
      "Step 600 Loss 6.38186e-05\n",
      "New data 29\n",
      "Step 0 Loss 0.175433\n",
      "Step 100 Loss 7.93335e-05\n",
      "Step 200 Loss 8.57432e-05\n",
      "Step 300 Loss 8.03509e-05\n",
      "Step 400 Loss 7.51187e-05\n",
      "Step 500 Loss 6.27093e-05\n",
      "Step 600 Loss 8.01981e-05\n",
      "New data 30\n",
      "Step 0 Loss 0.427555\n",
      "Step 100 Loss 6.06049e-05\n",
      "Step 200 Loss 6.3709e-05\n",
      "Step 300 Loss 6.50455e-05\n",
      "Step 400 Loss 6.77634e-05\n",
      "Step 500 Loss 6.68653e-05\n",
      "Step 600 Loss 6.60182e-05\n",
      "New data 31\n",
      "Step 0 Loss 0.194192\n",
      "Step 100 Loss 7.18305e-05\n",
      "Step 200 Loss 7.53234e-05\n",
      "Step 300 Loss 7.41825e-05\n",
      "Step 400 Loss 6.69431e-05\n",
      "Step 500 Loss 7.83092e-05\n",
      "Step 600 Loss 6.34561e-05\n",
      "New data 32\n",
      "Step 0 Loss 0.257274\n",
      "Step 100 Loss 6.04288e-05\n",
      "Step 200 Loss 6.63042e-05\n",
      "Step 300 Loss 7.35851e-05\n",
      "Step 400 Loss 6.51568e-05\n",
      "Step 500 Loss 6.56001e-05\n",
      "Step 600 Loss 6.60023e-05\n",
      "New data 33\n",
      "Step 0 Loss 0.205546\n",
      "Step 100 Loss 6.03505e-05\n",
      "Step 200 Loss 6.59197e-05\n",
      "Step 300 Loss 6.11673e-05\n",
      "Step 400 Loss 6.11023e-05\n",
      "Step 500 Loss 6.10912e-05\n",
      "Step 600 Loss 5.53648e-05\n",
      "New data 34\n",
      "Step 0 Loss 0.210347\n",
      "Step 100 Loss 7.09306e-05\n",
      "Step 200 Loss 7.24852e-05\n",
      "Step 300 Loss 8.10005e-05\n",
      "Step 400 Loss 6.16475e-05\n",
      "Step 500 Loss 6.5707e-05\n",
      "Step 600 Loss 6.6495e-05\n",
      "New data 35\n",
      "Step 0 Loss 0.262082\n",
      "Step 100 Loss 5.72023e-05\n",
      "Step 200 Loss 6.64174e-05\n",
      "Step 300 Loss 6.99904e-05\n",
      "Step 400 Loss 6.58023e-05\n",
      "Step 500 Loss 6.09515e-05\n",
      "Step 600 Loss 6.08037e-05\n",
      "New data 36\n",
      "Step 0 Loss 0.108998\n",
      "Step 100 Loss 6.36789e-05\n",
      "Step 200 Loss 5.98026e-05\n",
      "Step 300 Loss 6.25187e-05\n",
      "Step 400 Loss 6.24329e-05\n",
      "Step 500 Loss 6.16621e-05\n",
      "Step 600 Loss 5.82227e-05\n",
      "New data 37\n",
      "Step 0 Loss 0.3939\n",
      "Step 100 Loss 7.09116e-05\n",
      "Step 200 Loss 6.42572e-05\n",
      "Step 300 Loss 6.40125e-05\n",
      "Step 400 Loss 5.79189e-05\n",
      "Step 500 Loss 6.74663e-05\n",
      "Step 600 Loss 6.82561e-05\n",
      "New data 38\n",
      "Step 0 Loss 0.156556\n",
      "Step 100 Loss 4.88597e-05\n",
      "Step 200 Loss 6.05096e-05\n",
      "Step 300 Loss 5.94067e-05\n",
      "Step 400 Loss 6.02602e-05\n",
      "Step 500 Loss 5.67017e-05\n",
      "Step 600 Loss 5.61359e-05\n",
      "New data 39\n",
      "Step 0 Loss 0.289973\n",
      "Step 100 Loss 5.60448e-05\n",
      "Step 200 Loss 6.04522e-05\n",
      "Step 300 Loss 5.10959e-05\n",
      "Step 400 Loss 5.42124e-05\n",
      "Step 500 Loss 5.55553e-05\n",
      "Step 600 Loss 5.1663e-05\n",
      "New data 40\n",
      "Step 0 Loss 0.213609\n",
      "Step 100 Loss 5.9723e-05\n",
      "Step 200 Loss 6.23484e-05\n",
      "Step 300 Loss 6.08575e-05\n",
      "Step 400 Loss 6.07273e-05\n",
      "Step 500 Loss 5.97563e-05\n",
      "Step 600 Loss 5.61372e-05\n",
      "New data 41\n",
      "Step 0 Loss 0.46278\n",
      "Step 100 Loss 5.55158e-05\n",
      "Step 200 Loss 5.67634e-05\n",
      "Step 300 Loss 5.98216e-05\n",
      "Step 400 Loss 6.27267e-05\n",
      "Step 500 Loss 6.51363e-05\n",
      "Step 600 Loss 5.08322e-05\n",
      "New data 42\n",
      "Step 0 Loss 0.213615\n",
      "Step 100 Loss 5.74216e-05\n",
      "Step 200 Loss 5.40379e-05\n",
      "Step 300 Loss 5.48612e-05\n",
      "Step 400 Loss 5.4936e-05\n",
      "Step 500 Loss 5.24358e-05\n",
      "Step 600 Loss 5.37709e-05\n",
      "New data 43\n",
      "Step 0 Loss 0.171079\n",
      "Step 100 Loss 5.79332e-05\n",
      "Step 200 Loss 5.16698e-05\n",
      "Step 300 Loss 6.32115e-05\n",
      "Step 400 Loss 5.18666e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500 Loss 5.44002e-05\n",
      "Step 600 Loss 5.62739e-05\n",
      "New data 44\n",
      "Step 0 Loss 0.166741\n",
      "Step 100 Loss 5.7919e-05\n",
      "Step 200 Loss 5.15663e-05\n",
      "Step 300 Loss 5.61724e-05\n",
      "Step 400 Loss 5.51631e-05\n",
      "Step 500 Loss 5.30716e-05\n",
      "Step 600 Loss 4.70209e-05\n",
      "New data 45\n",
      "Step 0 Loss 0.165895\n",
      "Step 100 Loss 5.65293e-05\n",
      "Step 200 Loss 5.50356e-05\n",
      "Step 300 Loss 5.44939e-05\n",
      "Step 400 Loss 4.95749e-05\n",
      "Step 500 Loss 5.56746e-05\n",
      "Step 600 Loss 4.77073e-05\n",
      "New data 46\n",
      "Step 0 Loss 0.174083\n",
      "Step 100 Loss 5.97549e-05\n",
      "Step 200 Loss 4.63295e-05\n",
      "Step 300 Loss 5.83289e-05\n",
      "Step 400 Loss 4.81191e-05\n",
      "Step 500 Loss 5.71828e-05\n",
      "Step 600 Loss 5.64502e-05\n",
      "New data 47\n",
      "Step 0 Loss 0.204643\n",
      "Step 100 Loss 4.95663e-05\n",
      "Step 200 Loss 5.07335e-05\n",
      "Step 300 Loss 4.89248e-05\n",
      "Step 400 Loss 5.51088e-05\n",
      "Step 500 Loss 5.26837e-05\n",
      "Step 600 Loss 5.19999e-05\n",
      "New data 48\n",
      "Step 0 Loss 0.199352\n",
      "Step 100 Loss 5.03916e-05\n",
      "Step 200 Loss 5.00373e-05\n",
      "Step 300 Loss 4.60179e-05\n",
      "Step 400 Loss 5.03281e-05\n",
      "Step 500 Loss 5.04584e-05\n",
      "Step 600 Loss 4.53885e-05\n",
      "New data 49\n",
      "Step 0 Loss 0.135607\n",
      "Step 100 Loss 5.11164e-05\n",
      "Step 200 Loss 5.05331e-05\n",
      "Step 300 Loss 5.98615e-05\n",
      "Step 400 Loss 5.03643e-05\n",
      "Step 500 Loss 5.43503e-05\n",
      "Step 600 Loss 4.56918e-05\n",
      "New data 50\n",
      "Step 0 Loss 0.220263\n",
      "Step 100 Loss 5.10864e-05\n",
      "Step 200 Loss 5.09131e-05\n",
      "Step 300 Loss 4.49736e-05\n",
      "Step 400 Loss 5.5538e-05\n",
      "Step 500 Loss 4.37942e-05\n",
      "Step 600 Loss 4.62102e-05\n",
      "New data 51\n",
      "Step 0 Loss 0.243312\n",
      "Step 100 Loss 5.40154e-05\n",
      "Step 200 Loss 4.8367e-05\n",
      "Step 300 Loss 5.28331e-05\n",
      "Step 400 Loss 4.10862e-05\n",
      "Step 500 Loss 4.48703e-05\n",
      "Step 600 Loss 4.409e-05\n",
      "New data 52\n",
      "Step 0 Loss 0.0924862\n",
      "Step 100 Loss 4.58654e-05\n",
      "Step 200 Loss 4.43775e-05\n",
      "Step 300 Loss 4.6927e-05\n",
      "Step 400 Loss 4.48368e-05\n",
      "Step 500 Loss 3.80805e-05\n",
      "Step 600 Loss 4.48831e-05\n",
      "New data 53\n",
      "Step 0 Loss 0.179766\n",
      "Step 100 Loss 4.7377e-05\n",
      "Step 200 Loss 5.14583e-05\n",
      "Step 300 Loss 4.35212e-05\n",
      "Step 400 Loss 4.40997e-05\n",
      "Step 500 Loss 4.48737e-05\n",
      "Step 600 Loss 5.06765e-05\n",
      "New data 54\n",
      "Step 0 Loss 0.147412\n",
      "Step 100 Loss 4.28599e-05\n",
      "Step 200 Loss 4.52092e-05\n",
      "Step 300 Loss 4.25389e-05\n",
      "Step 400 Loss 3.926e-05\n",
      "Step 500 Loss 4.52377e-05\n",
      "Step 600 Loss 4.03488e-05\n",
      "New data 55\n",
      "Step 0 Loss 0.199552\n",
      "Step 100 Loss 4.49865e-05\n",
      "Step 200 Loss 4.21733e-05\n",
      "Step 300 Loss 3.99467e-05\n",
      "Step 400 Loss 4.09464e-05\n",
      "Step 500 Loss 4.24547e-05\n",
      "Step 600 Loss 4.10831e-05\n",
      "New data 56\n",
      "Step 0 Loss 0.166032\n",
      "Step 100 Loss 4.15726e-05\n",
      "Step 200 Loss 4.62533e-05\n",
      "Step 300 Loss 4.35211e-05\n",
      "Step 400 Loss 4.16441e-05\n",
      "Step 500 Loss 4.26343e-05\n",
      "Step 600 Loss 4.13548e-05\n",
      "New data 57\n",
      "Step 0 Loss 0.188619\n",
      "Step 100 Loss 5.24277e-05\n",
      "Step 200 Loss 4.35005e-05\n",
      "Step 300 Loss 4.46496e-05\n",
      "Step 400 Loss 4.04441e-05\n",
      "Step 500 Loss 4.31825e-05\n",
      "Step 600 Loss 3.98386e-05\n",
      "New data 58\n",
      "Step 0 Loss 0.562071\n",
      "Step 100 Loss 5.15087e-05\n",
      "Step 200 Loss 4.93284e-05\n",
      "Step 300 Loss 6.43166e-05\n",
      "Step 400 Loss 5.45811e-05\n",
      "Step 500 Loss 4.09113e-05\n",
      "Step 600 Loss 5.26646e-05\n",
      "New data 59\n",
      "Step 0 Loss 0.212899\n",
      "Step 100 Loss 4.10494e-05\n",
      "Step 200 Loss 4.3144e-05\n",
      "Step 300 Loss 4.74451e-05\n",
      "Step 400 Loss 4.72845e-05\n",
      "Step 500 Loss 5.55165e-05\n",
      "Step 600 Loss 4.99641e-05\n",
      "New data 60\n",
      "Step 0 Loss 0.280015\n",
      "Step 100 Loss 4.25881e-05\n",
      "Step 200 Loss 4.06397e-05\n",
      "Step 300 Loss 3.83955e-05\n",
      "Step 400 Loss 4.36753e-05\n",
      "Step 500 Loss 4.47576e-05\n",
      "Step 600 Loss 3.78263e-05\n",
      "New data 61\n",
      "Step 0 Loss 0.16154\n",
      "Step 100 Loss 4.35624e-05\n",
      "Step 200 Loss 3.93505e-05\n",
      "Step 300 Loss 4.28679e-05\n",
      "Step 400 Loss 4.21685e-05\n",
      "Step 500 Loss 4.71463e-05\n",
      "Step 600 Loss 4.47079e-05\n",
      "New data 62\n",
      "Step 0 Loss 0.150601\n",
      "Step 100 Loss 4.20016e-05\n",
      "Step 200 Loss 3.93426e-05\n",
      "Step 300 Loss 3.88737e-05\n",
      "Step 400 Loss 3.94666e-05\n",
      "Step 500 Loss 3.77199e-05\n",
      "Step 600 Loss 4.54314e-05\n",
      "New data 63\n",
      "Step 0 Loss 0.267789\n",
      "Step 100 Loss 4.23514e-05\n",
      "Step 200 Loss 4.70607e-05\n",
      "Step 300 Loss 4.2995e-05\n",
      "Step 400 Loss 4.10608e-05\n",
      "Step 500 Loss 4.53061e-05\n",
      "Step 600 Loss 3.77232e-05\n",
      "New data 64\n",
      "Step 0 Loss 0.211161\n",
      "Step 100 Loss 4.24547e-05\n",
      "Step 200 Loss 4.63884e-05\n",
      "Step 300 Loss 4.36562e-05\n",
      "Step 400 Loss 4.53616e-05\n",
      "Step 500 Loss 3.93538e-05\n",
      "Step 600 Loss 3.90247e-05\n",
      "New data 65\n",
      "Step 0 Loss 0.158275\n",
      "Step 100 Loss 4.08128e-05\n",
      "Step 200 Loss 4.71639e-05\n",
      "Step 300 Loss 5.0195e-05\n",
      "Step 400 Loss 3.83986e-05\n",
      "Step 500 Loss 3.99148e-05\n",
      "Step 600 Loss 3.78153e-05\n",
      "New data 66\n",
      "Step 0 Loss 0.251041\n",
      "Step 100 Loss 4.18426e-05\n",
      "Step 200 Loss 4.02978e-05\n",
      "Step 300 Loss 4.27023e-05\n",
      "Step 400 Loss 4.54076e-05\n",
      "Step 500 Loss 3.84065e-05\n",
      "Step 600 Loss 4.09097e-05\n",
      "New data 67\n",
      "Step 0 Loss 0.239226\n",
      "Step 100 Loss 4.78567e-05\n",
      "Step 200 Loss 4.6803e-05\n",
      "Step 300 Loss 4.38023e-05\n",
      "Step 400 Loss 3.72574e-05\n",
      "Step 500 Loss 3.85781e-05\n",
      "Step 600 Loss 4.52932e-05\n",
      "New data 68\n",
      "Step 0 Loss 0.141219\n",
      "Step 100 Loss 4.19158e-05\n",
      "Step 200 Loss 3.83604e-05\n",
      "Step 300 Loss 3.5908e-05\n",
      "Step 400 Loss 3.24479e-05\n",
      "Step 500 Loss 3.99277e-05\n",
      "Step 600 Loss 4.04123e-05\n",
      "New data 69\n",
      "Step 0 Loss 0.240199\n",
      "Step 100 Loss 4.02804e-05\n",
      "Step 200 Loss 4.40837e-05\n",
      "Step 300 Loss 4.06206e-05\n",
      "Step 400 Loss 3.3465e-05\n",
      "Step 500 Loss 3.98434e-05\n",
      "Step 600 Loss 3.93617e-05\n",
      "New data 70\n",
      "Step 0 Loss 0.145394\n",
      "Step 100 Loss 4.20859e-05\n",
      "Step 200 Loss 4.11672e-05\n",
      "Step 300 Loss 3.78852e-05\n",
      "Step 400 Loss 3.72384e-05\n",
      "Step 500 Loss 3.8494e-05\n",
      "Step 600 Loss 3.63054e-05\n",
      "New data 71\n",
      "Step 0 Loss 0.117195\n",
      "Step 100 Loss 3.64182e-05\n",
      "Step 200 Loss 3.7383e-05\n",
      "Step 300 Loss 3.45857e-05\n",
      "Step 400 Loss 3.78709e-05\n",
      "Step 500 Loss 3.98847e-05\n",
      "Step 600 Loss 2.86048e-05\n",
      "New data 72\n",
      "Step 0 Loss 0.164297\n",
      "Step 100 Loss 3.4716e-05\n",
      "Step 200 Loss 3.99514e-05\n",
      "Step 300 Loss 3.69807e-05\n",
      "Step 400 Loss 3.37003e-05\n",
      "Step 500 Loss 3.50815e-05\n",
      "Step 600 Loss 4.1997e-05\n",
      "New data 73\n",
      "Step 0 Loss 0.192823\n",
      "Step 100 Loss 3.51945e-05\n",
      "Step 200 Loss 3.32713e-05\n",
      "Step 300 Loss 3.94063e-05\n",
      "Step 400 Loss 3.71669e-05\n",
      "Step 500 Loss 3.81633e-05\n",
      "Step 600 Loss 3.64977e-05\n",
      "New data 74\n",
      "Step 0 Loss 0.220661\n",
      "Step 100 Loss 3.95779e-05\n",
      "Step 200 Loss 3.64993e-05\n",
      "Step 300 Loss 3.86101e-05\n",
      "Step 400 Loss 3.78376e-05\n",
      "Step 500 Loss 3.42074e-05\n",
      "Step 600 Loss 3.27611e-05\n",
      "New data 75\n",
      "Step 0 Loss 0.14217\n",
      "Step 100 Loss 3.57682e-05\n",
      "Step 200 Loss 3.12845e-05\n",
      "Step 300 Loss 3.17598e-05\n",
      "Step 400 Loss 3.68363e-05\n",
      "Step 500 Loss 3.42599e-05\n",
      "Step 600 Loss 3.74798e-05\n",
      "New data 76\n",
      "Step 0 Loss 0.130372\n",
      "Step 100 Loss 3.51833e-05\n",
      "Step 200 Loss 3.36606e-05\n",
      "Step 300 Loss 3.25688e-05\n",
      "Step 400 Loss 3.56824e-05\n",
      "Step 500 Loss 4.00707e-05\n",
      "Step 600 Loss 3.3977e-05\n",
      "New data 77\n",
      "Step 0 Loss 0.184835\n",
      "Step 100 Loss 2.86414e-05\n",
      "Step 200 Loss 3.40182e-05\n",
      "Step 300 Loss 3.46128e-05\n",
      "Step 400 Loss 3.54503e-05\n",
      "Step 500 Loss 3.2963e-05\n",
      "Step 600 Loss 3.65805e-05\n",
      "New data 78\n",
      "Step 0 Loss 0.137724\n",
      "Step 100 Loss 2.90037e-05\n",
      "Step 200 Loss 3.31537e-05\n",
      "Step 300 Loss 2.97476e-05\n",
      "Step 400 Loss 3.33157e-05\n",
      "Step 500 Loss 3.82873e-05\n",
      "Step 600 Loss 3.23637e-05\n",
      "New data 79\n",
      "Step 0 Loss 0.18249\n",
      "Step 100 Loss 3.21142e-05\n",
      "Step 200 Loss 3.60145e-05\n",
      "Step 300 Loss 4.33832e-05\n",
      "Step 400 Loss 3.68076e-05\n",
      "Step 500 Loss 3.77486e-05\n",
      "Step 600 Loss 3.39276e-05\n",
      "New data 80\n",
      "Step 0 Loss 0.421603\n",
      "Step 100 Loss 3.27198e-05\n",
      "Step 200 Loss 3.31902e-05\n",
      "Step 300 Loss 3.13671e-05\n",
      "Step 400 Loss 3.1275e-05\n",
      "Step 500 Loss 3.34811e-05\n",
      "Step 600 Loss 3.39118e-05\n",
      "New data 81\n",
      "Step 0 Loss 0.196014\n",
      "Step 100 Loss 3.26721e-05\n",
      "Step 200 Loss 3.29549e-05\n",
      "Step 300 Loss 3.51721e-05\n",
      "Step 400 Loss 3.56743e-05\n",
      "Step 500 Loss 3.37211e-05\n",
      "Step 600 Loss 3.17948e-05\n",
      "New data 82\n",
      "Step 0 Loss 0.158351\n",
      "Step 100 Loss 3.75785e-05\n",
      "Step 200 Loss 2.74859e-05\n",
      "Step 300 Loss 3.35241e-05\n",
      "Step 400 Loss 3.29916e-05\n",
      "Step 500 Loss 3.45095e-05\n",
      "Step 600 Loss 2.90086e-05\n",
      "New data 83\n",
      "Step 0 Loss 0.162655\n",
      "Step 100 Loss 3.14753e-05\n",
      "Step 200 Loss 2.93487e-05\n",
      "Step 300 Loss 3.29074e-05\n",
      "Step 400 Loss 3.1364e-05\n",
      "Step 500 Loss 3.35654e-05\n",
      "Step 600 Loss 3.19426e-05\n",
      "New data 84\n",
      "Step 0 Loss 0.215263\n",
      "Step 100 Loss 2.99209e-05\n",
      "Step 200 Loss 3.28804e-05\n",
      "Step 300 Loss 3.27087e-05\n",
      "Step 400 Loss 3.12862e-05\n",
      "Step 500 Loss 3.14785e-05\n",
      "Step 600 Loss 2.88274e-05\n",
      "New data 85\n",
      "Step 0 Loss 0.172306\n",
      "Step 100 Loss 3.25958e-05\n",
      "Step 200 Loss 2.6324e-05\n",
      "Step 300 Loss 2.80755e-05\n",
      "Step 400 Loss 3.16978e-05\n",
      "Step 500 Loss 3.0776e-05\n",
      "Step 600 Loss 3.66408e-05\n",
      "New data 86\n",
      "Step 0 Loss 0.19171\n",
      "Step 100 Loss 3.57092e-05\n",
      "Step 200 Loss 3.28501e-05\n",
      "Step 300 Loss 3.31013e-05\n",
      "Step 400 Loss 3.44999e-05\n",
      "Step 500 Loss 3.18266e-05\n",
      "Step 600 Loss 3.19266e-05\n",
      "New data 87\n",
      "Step 0 Loss 0.199914\n",
      "Step 100 Loss 2.56755e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200 Loss 3.11097e-05\n",
      "Step 300 Loss 3.23125e-05\n",
      "Step 400 Loss 3.26116e-05\n",
      "Step 500 Loss 3.11286e-05\n",
      "Step 600 Loss 3.20936e-05\n",
      "New data 88\n",
      "Step 0 Loss 0.138011\n",
      "Step 100 Loss 3.02578e-05\n",
      "Step 200 Loss 3.04389e-05\n",
      "Step 300 Loss 3.23812e-05\n",
      "Step 400 Loss 3.1979e-05\n",
      "Step 500 Loss 3.08808e-05\n",
      "Step 600 Loss 3.0474e-05\n",
      "New data 89\n",
      "Step 0 Loss 0.169879\n",
      "Step 100 Loss 3.28183e-05\n",
      "Step 200 Loss 3.39929e-05\n",
      "Step 300 Loss 3.0989e-05\n",
      "Step 400 Loss 3.86015e-05\n",
      "Step 500 Loss 2.80565e-05\n",
      "Step 600 Loss 3.13815e-05\n",
      "New data 90\n",
      "Step 0 Loss 0.31341\n",
      "Step 100 Loss 3.08141e-05\n",
      "Step 200 Loss 3.44141e-05\n",
      "Step 300 Loss 3.07474e-05\n",
      "Step 400 Loss 3.45079e-05\n",
      "Step 500 Loss 3.43808e-05\n",
      "Step 600 Loss 3.06616e-05\n",
      "New data 91\n",
      "Step 0 Loss 0.172001\n",
      "Step 100 Loss 3.46144e-05\n",
      "Step 200 Loss 2.87114e-05\n",
      "Step 300 Loss 2.81202e-05\n",
      "Step 400 Loss 3.39374e-05\n",
      "Step 500 Loss 3.00799e-05\n",
      "Step 600 Loss 3.35447e-05\n",
      "New data 92\n",
      "Step 0 Loss 0.210925\n",
      "Step 100 Loss 2.93328e-05\n",
      "Step 200 Loss 2.90228e-05\n",
      "Step 300 Loss 3.17186e-05\n",
      "Step 400 Loss 3.10414e-05\n",
      "Step 500 Loss 3.30583e-05\n",
      "Step 600 Loss 3.05773e-05\n",
      "New data 93\n",
      "Step 0 Loss 0.214032\n",
      "Step 100 Loss 3.16009e-05\n",
      "Step 200 Loss 2.74462e-05\n",
      "Step 300 Loss 2.70997e-05\n",
      "Step 400 Loss 3.49542e-05\n",
      "Step 500 Loss 3.33413e-05\n",
      "Step 600 Loss 3.43378e-05\n",
      "New data 94\n",
      "Step 0 Loss 0.138562\n",
      "Step 100 Loss 3.28963e-05\n",
      "Step 200 Loss 3.02658e-05\n",
      "Step 300 Loss 2.68708e-05\n",
      "Step 400 Loss 2.94409e-05\n",
      "Step 500 Loss 3.18647e-05\n",
      "Step 600 Loss 2.78277e-05\n",
      "New data 95\n",
      "Step 0 Loss 0.0973336\n",
      "Step 100 Loss 3.3052e-05\n",
      "Step 200 Loss 2.8759e-05\n",
      "Step 300 Loss 2.61429e-05\n",
      "Step 400 Loss 3.0412e-05\n",
      "Step 500 Loss 2.80565e-05\n",
      "Step 600 Loss 2.61842e-05\n",
      "New data 96\n",
      "Step 0 Loss 0.199336\n",
      "Step 100 Loss 3.18867e-05\n",
      "Step 200 Loss 2.80644e-05\n",
      "Step 300 Loss 3.09175e-05\n",
      "Step 400 Loss 3.00131e-05\n",
      "Step 500 Loss 2.72269e-05\n",
      "Step 600 Loss 3.16502e-05\n",
      "New data 97\n",
      "Step 0 Loss 0.222075\n",
      "Step 100 Loss 2.83553e-05\n",
      "Step 200 Loss 2.92899e-05\n",
      "Step 300 Loss 3.05026e-05\n",
      "Step 400 Loss 2.89974e-05\n",
      "Step 500 Loss 2.98605e-05\n",
      "Step 600 Loss 2.79771e-05\n",
      "New data 98\n",
      "Step 0 Loss 0.160507\n",
      "Step 100 Loss 3.16708e-05\n",
      "Step 200 Loss 2.85047e-05\n",
      "Step 300 Loss 3.05106e-05\n",
      "Step 400 Loss 2.78213e-05\n",
      "Step 500 Loss 3.08998e-05\n",
      "Step 600 Loss 2.81296e-05\n",
      "New data 99\n",
      "Step 0 Loss 0.176291\n",
      "Step 100 Loss 2.50414e-05\n",
      "Step 200 Loss 2.6011e-05\n",
      "Step 300 Loss 2.6216e-05\n",
      "Step 400 Loss 2.98652e-05\n",
      "Step 500 Loss 2.9371e-05\n",
      "Step 600 Loss 2.66245e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYoVvsswAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f655c33be80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    plt.ion()\n",
    "    plt.figure()\n",
    "    plt.show()\n",
    "    loss_list = []\n",
    "    \n",
    "    for epoch_idx in range(num_epochs):\n",
    "        x, y = generateData()\n",
    "        _current_state = np.zeros((batch_size, state_size))\n",
    "        \n",
    "        print ('New data', epoch_idx)\n",
    "        \n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * truncated_backprop_length\n",
    "            end_idx = start_idx + truncated_backprop_length\n",
    "            \n",
    "            batchX = x[:, start_idx: end_idx]\n",
    "            batchY = y[:, start_idx: end_idx]\n",
    "            \n",
    "            _total_loss, _train_step, _current_state, _prediction_series = sess.run(\n",
    "            [total_loss, train_step, current_state, prediction_series],\n",
    "            feed_dict = {\n",
    "                x_placeholder: batchX,\n",
    "                y_placeholder: batchY,\n",
    "                init_state: _current_state\n",
    "            })\n",
    "            \n",
    "            loss_list.append(_total_loss)\n",
    "            \n",
    "            if batch_idx % 100 ==0:\n",
    "                print('Step', batch_idx, 'Loss', _total_loss)\n",
    "                plot(loss_list, _prediction_series, batchX, batchY)\n",
    "                \n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
